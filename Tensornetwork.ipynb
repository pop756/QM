{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensornetwork as tn\n",
    "import numpy as np\n",
    "import tensornetwork as tn\n",
    "class TNLayer(tf.keras.layers.Layer):\n",
    " \n",
    "  def __init__(self,Tensor_dimention = 20):\n",
    "    super(TNLayer, self).__init__()\n",
    "    # Create the variables for the layer.\n",
    "    \n",
    "\n",
    "    self.A1 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,4], stddev=1.0/192.0),name=\"a1\", trainable=True)\n",
    "    self.A2 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,Tensor_dimention,4], stddev=1.0/192.0),name=\"a2\", trainable=True)\n",
    "    self.A3 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,Tensor_dimention,4], stddev=1.0/192.0),name=\"a3\", trainable=True)\n",
    "    self.A4 = tf.Variable(tf.random.normal(shape=[4,Tensor_dimention,3], stddev=1.0/192.0),name=\"a4\", trainable=True)\n",
    "    Nodes = [tn.Node(self.A1,'a0',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A2,f'a{1}',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A3,f'a{2}',backend=\"tensorflow\")]\n",
    "    Nodes+=[tn.Node(self.A4,f'a{3}',backend=\"tensorflow\")]\n",
    "    self.Nodes = Nodes\n",
    "\n",
    "    self.bias = tf.Variable(tf.zeros(shape=(192)), name=\"bias\", trainable=True)\n",
    " \n",
    "  def call(self, inputs):\n",
    "    # Define the contraction.\n",
    "    # We break it out so we can parallelize a batch using\n",
    "    # tf.vectorized_map (see below).\n",
    "    def f(input_vec, Nodes, bias_var):\n",
    "      # Reshape to a matrix instead of a vector.\n",
    "      input_vec = tf.reshape(input_vec, [200,4,4,4,4])\n",
    "      T_node = tn.Node(input_vec, backend=\"tensorflow\",name = 't')\n",
    "      for i in range(len(Nodes)-1):\n",
    "        if i == 0:\n",
    "          Nodes[i][1]^Nodes[i+1][1]\n",
    "        else:\n",
    "          Nodes[i][2]^Nodes[i+1][1]\n",
    "      for i in range(len(Nodes)):\n",
    "        Nodes[i][0]^T_node[i+1]    \n",
    "      \n",
    "      contraction = T_node@Nodes[0]\n",
    "      for i in range(1,len(Nodes)):\n",
    "        contraction = contraction@Nodes[i]\n",
    "      result = tf.reshape(contraction.tensor,[200,192])\n",
    "\n",
    "      # To make the code shorter, we also could've used Ncon.\n",
    "      # The above few lines of code is the same as this:\n",
    "      # result = tn.ncon([x, a_var, b_var], [[1, 2], [-1, 1, 3], [-2, 2, 3]])\n",
    " \n",
    "      # Finally, add bias.\n",
    "      return result + bias_var\n",
    "  \n",
    "    # To deal with a batch of items, we can use the tf.vectorized_map\n",
    "    # function.\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/vectorized_map\n",
    "    result = tf.vectorized_map(\n",
    "        lambda vec: f(vec, self.Nodes, self.bias), inputs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = TNLayer()\n",
    "A = np.random.random([200,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 200, 192), dtype=float32, numpy=\n",
       "array([[[-1.76473222e-07, -2.09265735e-07,  7.39498830e-07, ...,\n",
       "         -2.46141212e-07, -4.91976607e-07, -2.20541722e-07],\n",
       "        [-4.70632216e-07,  1.96382473e-07,  6.70125814e-07, ...,\n",
       "         -2.51511494e-07,  5.84928443e-08, -2.76010695e-07],\n",
       "        [-4.30301185e-07, -5.17214914e-07,  2.57740169e-07, ...,\n",
       "         -9.67300025e-07,  1.27597076e-07,  1.60715715e-07],\n",
       "        ...,\n",
       "        [ 1.22441492e-07, -3.13303929e-07,  4.55734607e-07, ...,\n",
       "         -8.24273741e-07,  2.66894688e-07, -1.89861552e-07],\n",
       "        [-1.18806774e-07,  1.51035749e-07,  2.93237520e-07, ...,\n",
       "         -3.77316418e-08,  6.13446559e-07, -2.28804339e-07],\n",
       "        [-2.27619466e-07, -1.52075927e-07, -3.76411080e-08, ...,\n",
       "         -6.16560758e-09, -1.70559659e-07, -1.19754844e-07]],\n",
       "\n",
       "       [[-1.76473222e-07, -2.09265735e-07,  7.39498830e-07, ...,\n",
       "         -2.46141212e-07, -4.91976607e-07, -2.20541722e-07],\n",
       "        [-4.70632216e-07,  1.96382473e-07,  6.70125814e-07, ...,\n",
       "         -2.51511494e-07,  5.84928443e-08, -2.76010695e-07],\n",
       "        [-4.30301185e-07, -5.17214914e-07,  2.57740169e-07, ...,\n",
       "         -9.67300025e-07,  1.27597076e-07,  1.60715715e-07],\n",
       "        ...,\n",
       "        [ 1.22441492e-07, -3.13303929e-07,  4.55734607e-07, ...,\n",
       "         -8.24273741e-07,  2.66894688e-07, -1.89861552e-07],\n",
       "        [-1.18806774e-07,  1.51035749e-07,  2.93237520e-07, ...,\n",
       "         -3.77316418e-08,  6.13446559e-07, -2.28804339e-07],\n",
       "        [-2.27619466e-07, -1.52075927e-07, -3.76411080e-08, ...,\n",
       "         -6.16560758e-09, -1.70559659e-07, -1.19754844e-07]],\n",
       "\n",
       "       [[-1.76473222e-07, -2.09265735e-07,  7.39498830e-07, ...,\n",
       "         -2.46141212e-07, -4.91976607e-07, -2.20541722e-07],\n",
       "        [-4.70632216e-07,  1.96382473e-07,  6.70125814e-07, ...,\n",
       "         -2.51511494e-07,  5.84928443e-08, -2.76010695e-07],\n",
       "        [-4.30301185e-07, -5.17214914e-07,  2.57740169e-07, ...,\n",
       "         -9.67300025e-07,  1.27597076e-07,  1.60715715e-07],\n",
       "        ...,\n",
       "        [ 1.22441492e-07, -3.13303929e-07,  4.55734607e-07, ...,\n",
       "         -8.24273741e-07,  2.66894688e-07, -1.89861552e-07],\n",
       "        [-1.18806774e-07,  1.51035749e-07,  2.93237520e-07, ...,\n",
       "         -3.77316418e-08,  6.13446559e-07, -2.28804339e-07],\n",
       "        [-2.27619466e-07, -1.52075927e-07, -3.76411080e-08, ...,\n",
       "         -6.16560758e-09, -1.70559659e-07, -1.19754844e-07]],\n",
       "\n",
       "       [[-1.76473222e-07, -2.09265735e-07,  7.39498830e-07, ...,\n",
       "         -2.46141212e-07, -4.91976607e-07, -2.20541722e-07],\n",
       "        [-4.70632216e-07,  1.96382473e-07,  6.70125814e-07, ...,\n",
       "         -2.51511494e-07,  5.84928443e-08, -2.76010695e-07],\n",
       "        [-4.30301185e-07, -5.17214914e-07,  2.57740169e-07, ...,\n",
       "         -9.67300025e-07,  1.27597076e-07,  1.60715715e-07],\n",
       "        ...,\n",
       "        [ 1.22441492e-07, -3.13303929e-07,  4.55734607e-07, ...,\n",
       "         -8.24273741e-07,  2.66894688e-07, -1.89861552e-07],\n",
       "        [-1.18806774e-07,  1.51035749e-07,  2.93237520e-07, ...,\n",
       "         -3.77316418e-08,  6.13446559e-07, -2.28804339e-07],\n",
       "        [-2.27619466e-07, -1.52075927e-07, -3.76411080e-08, ...,\n",
       "         -6.16560758e-09, -1.70559659e-07, -1.19754844e-07]],\n",
       "\n",
       "       [[-1.76473222e-07, -2.09265735e-07,  7.39498830e-07, ...,\n",
       "         -2.46141212e-07, -4.91976607e-07, -2.20541722e-07],\n",
       "        [-4.70632216e-07,  1.96382473e-07,  6.70125814e-07, ...,\n",
       "         -2.51511494e-07,  5.84928443e-08, -2.76010695e-07],\n",
       "        [-4.30301185e-07, -5.17214914e-07,  2.57740169e-07, ...,\n",
       "         -9.67300025e-07,  1.27597076e-07,  1.60715715e-07],\n",
       "        ...,\n",
       "        [ 1.22441492e-07, -3.13303929e-07,  4.55734607e-07, ...,\n",
       "         -8.24273741e-07,  2.66894688e-07, -1.89861552e-07],\n",
       "        [-1.18806774e-07,  1.51035749e-07,  2.93237520e-07, ...,\n",
       "         -3.77316418e-08,  6.13446559e-07, -2.28804339e-07],\n",
       "        [-2.27619466e-07, -1.52075927e-07, -3.76411080e-08, ...,\n",
       "         -6.16560758e-09, -1.70559659e-07, -1.19754844e-07]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN(np.array([A,A,A,A,A]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 200, 256)\n",
      "(48, 2, 200, 32)\n",
      "Multihead Attention Output shape: (48, 200, 256)\n",
      "Attention Weights shape: (48, 8, 200, 200)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiheadAttention_tensor(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads,classical_rate = 0.25,Tensor_dimention = 20):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "        self.rate = classical_rate\n",
    "        assert int(num_heads/classical_rate) == num_heads/classical_rate\n",
    "\n",
    "\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(int(d_model*classical_rate))\n",
    "        self.wk = tf.keras.layers.Dense(int(d_model*classical_rate))\n",
    "        self.wv = tf.keras.layers.Dense(int(d_model*classical_rate))\n",
    "\n",
    "        self.wq_tensor = TNLayer(Tensor_dimention)\n",
    "        self.wk_tensor = TNLayer(Tensor_dimention)\n",
    "        self.wv_tensor = TNLayer(Tensor_dimention)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, int(self.num_heads*self.rate), self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def split_heads_tensor(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, int(self.num_heads*(1-self.rate)), self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        print(q.shape)\n",
    "        q_class = self.split_heads(self.wq(q), batch_size)\n",
    "        k_class = self.split_heads(self.wk(k), batch_size)\n",
    "        v_class = self.split_heads(self.wv(v), batch_size)\n",
    "        print(q_class.shape)\n",
    "        q_tensor = self.split_heads_tensor(self.wq_tensor(q),batch_size)\n",
    "        k_tensor = self.split_heads_tensor(self.wq_tensor(k),batch_size)\n",
    "        v_tensor = self.split_heads_tensor(self.wq_tensor(v),batch_size)\n",
    "        q,k,v = tf.concat([q_class,q_tensor],axis=1),tf.concat([k_class,k_tensor],axis=1),tf.concat([v_class,v_tensor],axis=1)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "\n",
    "# 테스트\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "input_seq_len = 200\n",
    "batch_size = 48\n",
    "\n",
    "multihead_attention = MultiheadAttention(d_model, num_heads,Tensor_dimention=15)\n",
    "input_q = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_k = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_v = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "mask = None  # Optional mask to specify which positions should be masked\n",
    "output, attention_weights = multihead_attention(input_q, input_k, input_v, mask)\n",
    "print(\"Multihead Attention Output shape:\", output.shape)\n",
    "print(\"Attention Weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138572"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 8, 200, 32)\n",
      "Multihead Attention Output shape: (4096, 200, 256)\n",
      "Attention Weights shape: (4096, 8, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MultiheadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model // num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.split_heads(self.wq(q), batch_size)\n",
    "        k = self.split_heads(self.wk(k), batch_size)\n",
    "        v = self.split_heads(self.wv(v), batch_size)\n",
    "        print(q.shape)\n",
    "\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights\n",
    "\n",
    "# 테스트\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "input_seq_len = 200\n",
    "batch_size = 4096\n",
    "\n",
    "multihead_attention = MultiheadAttention(d_model, num_heads)\n",
    "input_q = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_k = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "input_v = tf.random.normal((batch_size, input_seq_len, d_model))\n",
    "mask = None  # Optional mask to specify which positions should be masked\n",
    "\n",
    "output, attention_weights = multihead_attention(input_q, input_k, input_v, mask)\n",
    "print(\"Multihead Attention Output shape:\", output.shape)\n",
    "print(\"Attention Weights shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'multihead_attention_1/dense_4/bias:0' shape=(256,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.trainable_variables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attention.count_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
