{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import csv\n",
    "smiles = []\n",
    "with open('./data/token/atom_In_Smiles_1M_tokken','rb') as file:\n",
    "  tok_smiles = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yslee/Downloads/Qunova-machine/Data_process.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39matomInSmiles\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m smiles \u001b[39m=\u001b[39m train[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# SMILES -> atom-in-SMILES \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ais_tokens \u001b[39m=\u001b[39m atomInSmiles\u001b[39m.\u001b[39mencode(smiles) \u001b[39m# '[NH2;!R;C] [CH2;!R;CN] [C;!R;COO] ( = [O;!R;C] ) [OH;!R;C]'\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import atomInSmiles\n",
    "smiles = train[0]\n",
    "\n",
    "# SMILES -> atom-in-SMILES \n",
    "ais_tokens = atomInSmiles.encode(smiles) # '[NH2;!R;C] [CH2;!R;CN] [C;!R;COO] ( = [O;!R;C] ) [OH;!R;C]'\n",
    "\n",
    "# atom-in-SMILES -> SMILES\n",
    "decoded_smiles = atomInSmiles.decode(ais_tokens) #'NCC(=O)O'\n",
    "\n",
    "assert smiles == decoded_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = smiles[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tok_smile = []\n",
    "for i in tqdm(smiles):\n",
    "    tok_smile.append(atomInSmiles.encode(i).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 02:43:29.092037: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-15 02:43:29.127269: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 02:43:29.127295: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 02:43:29.127321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 02:43:29.133745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Processing the token\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yslee/Downloads/Qunova-machine/Data_process.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtdc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msingle_pred\u001b[39;00m \u001b[39mimport\u001b[39;00m Tox\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train,tox_info \u001b[39m=\u001b[39m Tox(name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mherg_karim\u001b[39m\u001b[39m'\u001b[39m )\u001b[39m.\u001b[39mget_data(\u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDeepPurpose\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train_set \u001b[39m=\u001b[39m rk\u001b[39m.\u001b[39msmile_tokenize(train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rk' is not defined"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import Tox\n",
    "train,tox_info = Tox(name = 'herg_karim' ).get_data(format = 'DeepPurpose')\n",
    "train_set = rk.smile_tokenize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox_info.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "for i in train:\n",
    "    tok_smile.append(atomInSmiles.encode(i).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok_smiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yslee/Downloads/Qunova-machine/Data_process.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Drop out len 1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m drop_train \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m index,sentence \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tok_smiles):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sentence)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         drop_train\u001b[39m.\u001b[39mappend(index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tok_smiles' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## Drop out len 1\n",
    "drop_train = []\n",
    "for index,sentence in enumerate(tok_smiles):\n",
    "    if len(sentence)<=1:\n",
    "        drop_train.append(index)\n",
    "        print(index)\n",
    "drop_sentence = []  \n",
    "\n",
    "temp_ = []\n",
    "for i,index in enumerate(drop_train):\n",
    "    temp_.append(drop_train[index-i])\n",
    "    tok_smile.pop(index-i)\n",
    "\n",
    "\n",
    "tokenized_doc = tok_smiles\n",
    "print('총 샘플 수 :',len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_doc[0]\n",
    "\n",
    "for i in tokenized_doc:\n",
    "    i.insert(0,'<CAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yslee/Downloads/Qunova-machine/Data_process.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tokenized_doc:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c6565227d/home/yslee/Downloads/Qunova-machine/Data_process.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     i\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m<END>\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_doc' is not defined"
     ]
    }
   ],
   "source": [
    "for i in tokenized_doc:\n",
    "    i.append('<END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "index = 0\n",
    "for i in tokenized_doc[:10000000]:\n",
    "    for j in i:\n",
    "        try:\n",
    "            temp_dict[j]\n",
    "        except:\n",
    "            temp_dict[j] = index\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(tok_smiles)\n",
    "\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {value : key for key, value in word2idx.items()}\n",
    "# index encoding\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word size : 167\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1 \n",
    "print('Word size :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the result\n",
    "\n",
    "with open('./Large_mol_tokken/AtomInsmiles/encoded.pkl','wb') as file:\n",
    "    pickle.dump(encoded,file)\n",
    "    \n",
    "with open('./Large_mol_tokken/AtomInsmiles/words.pkl','wb') as file:\n",
    "    pickle.dump(word2idx,file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the result\n",
    "import pickle\n",
    "\n",
    "with open('./Large_mol_tokken/AtomInsmiles/encoded.pkl','rb') as file:\n",
    "    encoded = pickle.load(file)\n",
    "    \n",
    "with open('./Large_mol_tokken/AtomInsmiles/words.pkl','rb') as file:\n",
    "    word2idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 256)       298752      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 256)       298752      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 1)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1)            0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 597,504\n",
      "Trainable params: 597,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 14:17:48.673340: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 14:17:49.589547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 308 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:ca:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "## model\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "embedding_dim = 256\n",
    "\n",
    "# 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "word_embedding = Embedding(vocab_size+1000, embedding_dim)(w_inputs)\n",
    "\n",
    "# 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "context_embedding  = Embedding(vocab_size+1000, embedding_dim)(c_inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import SVG\n",
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
    "output = Activation('sigmoid')(dot_product)\n",
    "\n",
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1470284/1470284 [11:57<00:00, 2048.78it/s]\n",
      "1470284it [02:45, 8866.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "37475/37475 [==============================] - 447s 12ms/step - loss: 0.2520 - acc: 0.8998\n",
      "Epoch 2/40\n",
      "37475/37475 [==============================] - 321s 9ms/step - loss: 0.2508 - acc: 0.9001\n",
      "Epoch 3/40\n",
      "37475/37475 [==============================] - 322s 9ms/step - loss: 0.2507 - acc: 0.9002\n",
      "Epoch 4/40\n",
      "37475/37475 [==============================] - 319s 9ms/step - loss: 0.2507 - acc: 0.9002\n",
      "Epoch 5/40\n",
      "37475/37475 [==============================] - 299s 8ms/step - loss: 0.2507 - acc: 0.9002\n",
      "Epoch 6/40\n",
      "37475/37475 [==============================] - 346s 9ms/step - loss: 0.2507 - acc: 0.9002\n",
      "Epoch 7/40\n",
      "37475/37475 [==============================] - 290s 8ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 8/40\n",
      "37475/37475 [==============================] - 325s 9ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 9/40\n",
      "37475/37475 [==============================] - 326s 9ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 10/40\n",
      "37475/37475 [==============================] - 305s 8ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 11/40\n",
      "37475/37475 [==============================] - 319s 9ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 12/40\n",
      "37475/37475 [==============================] - 338s 9ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 13/40\n",
      "37475/37475 [==============================] - 316s 8ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 14/40\n",
      "37475/37475 [==============================] - 296s 8ms/step - loss: 0.2506 - acc: 0.9002\n",
      "Epoch 15/40\n",
      "37475/37475 [==============================] - 341s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 16/40\n",
      "37475/37475 [==============================] - 316s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 17/40\n",
      "37475/37475 [==============================] - 296s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 18/40\n",
      "37475/37475 [==============================] - 339s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 19/40\n",
      "37475/37475 [==============================] - 336s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 20/40\n",
      "37475/37475 [==============================] - 277s 7ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 21/40\n",
      "37475/37475 [==============================] - 401s 11ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 22/40\n",
      "37475/37475 [==============================] - 303s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 23/40\n",
      "37475/37475 [==============================] - 328s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 24/40\n",
      "37475/37475 [==============================] - 411s 11ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 25/40\n",
      "37475/37475 [==============================] - 295s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 26/40\n",
      "37475/37475 [==============================] - 316s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 27/40\n",
      "37475/37475 [==============================] - 341s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 28/40\n",
      "37475/37475 [==============================] - 355s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 29/40\n",
      "37475/37475 [==============================] - 325s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 30/40\n",
      "37475/37475 [==============================] - 384s 10ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 31/40\n",
      "37475/37475 [==============================] - 333s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 32/40\n",
      "37475/37475 [==============================] - 280s 7ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 33/40\n",
      "37475/37475 [==============================] - 342s 9ms/step - loss: 0.2505 - acc: 0.9003\n",
      "Epoch 34/40\n",
      "37475/37475 [==============================] - 326s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 35/40\n",
      "37475/37475 [==============================] - 303s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 36/40\n",
      "37475/37475 [==============================] - 305s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 37/40\n",
      "37475/37475 [==============================] - 319s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 38/40\n",
      "37475/37475 [==============================] - 303s 8ms/step - loss: 0.2505 - acc: 0.9002\n",
      "Epoch 39/40\n",
      "37475/37475 [==============================] - 363s 10ms/step - loss: 0.2505 - acc: 0.9003\n",
      "Epoch 40/40\n",
      "37475/37475 [==============================] - 355s 9ms/step - loss: 0.2505 - acc: 0.9002\n",
      "INFO:tensorflow:Assets written to: Large_mol_tokken/AtomInsmiles/L_model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "import numpy as np\n",
    "#validation\n",
    "skip_temp = []\n",
    "first_em_val = []\n",
    "second_em_val = []\n",
    "y_123_val = []\n",
    "\n",
    "\n",
    "for itter in range(1):\n",
    "    skip_gram = []\n",
    "    first_em = []\n",
    "    second_em = []\n",
    "    y_123 = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(encoded))):\n",
    "        skip_gram.append(skipgrams(encoded[i], vocabulary_size=vocab_size, window_size=3))\n",
    "        \n",
    "        \n",
    "    for _, elem in tqdm(enumerate(skip_gram)):\n",
    "        if len(elem[1]) == 0:\n",
    "            print('pass')\n",
    "            continue\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        try:\n",
    "            labels = np.array(elem[1].get(),dtype='int32')\n",
    "        except:\n",
    "            labels = np.array(elem[1],dtype='int32')\n",
    "        for i in first_elem:\n",
    "            first_em.append(i)\n",
    "        for j in second_elem:\n",
    "            second_em.append(j)\n",
    "        for k in labels:\n",
    "            y_123.append(k)\n",
    "            \n",
    "    second_em =np.array(second_em,dtype='int32')\n",
    "    first_em =np.array(first_em,dtype='int32')\n",
    "    y_123 = np.array(y_123,dtype='int32')\n",
    "\n",
    "\n",
    "    with tf.device(\"/device:GPU:0\"):\n",
    "        model.fit([first_em,second_em],y_123,epochs=40,batch_size=10000)\n",
    "    model.save('Large_mol_tokken/AtomInsmiles/L_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_gram = []\n",
    "first_em = []\n",
    "second_em = []\n",
    "y_123 = []\n",
    "for i in tqdm(range(len(encoded_add))):\n",
    "    skip_gram.append(skipgrams(encoded_add[i], vocabulary_size=vocab_size, window_size=3))\n",
    "        \n",
    "for _, elem in tqdm(enumerate(skip_gram)):\n",
    "    if len(elem[1]) == 0:\n",
    "        print('pass')\n",
    "        continue\n",
    "    first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "    second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "    try:\n",
    "        labels = np.array(elem[1].get(),dtype='int32')\n",
    "    except:\n",
    "        labels = np.array(elem[1],dtype='int32')\n",
    "    for i in first_elem:\n",
    "        first_em.append(i)\n",
    "    for j in second_elem:\n",
    "        second_em.append(j)\n",
    "    for k in labels:\n",
    "        y_123.append(k)\n",
    "        \n",
    "second_em =np.array(second_em,dtype='int32')\n",
    "first_em =np.array(first_em,dtype='int32')\n",
    "y_123 = np.array(y_123,dtype='int32')\n",
    "\n",
    "\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit([first_em,second_em],y_123,epochs=40,batch_size=1000000,validation_data=([first_em_val,second_em_val], y_123_val))\n",
    "model.save('Large_mol_tokken/L_model_tuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "import gensim\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "f = open('./Large_mol_tokken/AtomInsmiles/w2v.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-1, 256))\n",
    "vectors = model.get_weights()[0]\n",
    "for word, i in word2idx.items():\n",
    "    f.write('{} {}\\n'.format(word, ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()\n",
    "\n",
    "# 모델 로드\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./Large_mol_tokken/AtomInsmiles/w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
