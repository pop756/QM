{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import execute_tensor as execute\n",
    "from execute_tensor import execute as exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from execute import tox_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module import custom_layers\n",
    "import tensorflow as tf\n",
    "\n",
    "BERT_tensor = custom_layers.BERT_tensor\n",
    "\n",
    "bert_layer = BERT_tensor(256,6,1024,strat_index=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tox_process('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from execute_tensor import predict\n",
    "\n",
    "with open('./BERT/SMILE/1M_random_ZINC_word2index.pkl','rb') as file:\n",
    "    word2idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "inputs = tf.keras.layers.Input(shape = (200,),dtype=tf.int32)\n",
    "outputs = bert_layer(inputs,None)\n",
    "\n",
    "model = Model(inputs = [inputs], outputs = [outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./BERT/SMILE/Pre_BERT.pkl','rb') as file:\n",
    "    paras = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(paras)\n",
    "paras = model.get_weights()\n",
    "bert_layer.set_weights(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def Task_mask(num_task):\n",
    "    result = np.zeros([200,200])\n",
    "    for i in range(num_task):\n",
    "        for j in range(200):\n",
    "            if j == i:\n",
    "                continue\n",
    "            else:\n",
    "                result[j][i] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Task_mask(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "Models = []\n",
    "\n",
    "Input = tf.keras.layers.Input(200,)\n",
    "hidden = bert_layer(Input,att_mask = mask)\n",
    "output = hidden[:,0]\n",
    "output = tf.keras.layers.Dense(1,activation = 'sigmoid')(output)\n",
    "globals()[f'Task{0}_model'] = Model(inputs = [Input],outputs = [output])\n",
    "globals()[f'Task{0}_model'].compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),loss = 'binary_crossentropy',metrics=['acc',AUC(name='auc')])\n",
    "Models.append(globals()[f'Task{0}_model'])\n",
    "\n",
    "for i in range(9):\n",
    "    i = i+1\n",
    "    Input = tf.keras.layers.Input(200,)\n",
    "    hidden = bert_layer(Input,att_mask = mask)\n",
    "    output = hidden[:,i]\n",
    "    output = tf.keras.layers.Dense(1,activation = 'sigmoid')(output)\n",
    "    globals()[f'Task{i}_model'] = Model(inputs = [Input],outputs = [output])\n",
    "    globals()[f'Task{i}_model'].compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5),loss = 'binary_crossentropy',metrics=['acc',AUC(name='auc')])\n",
    "    Models.append(globals()[f'Task{i}_model'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./BERT/SMILE/1M_random_ZINC_word2index.pkl','rb') as file:\n",
    "    word2idx = pickle.load(file)\n",
    "def w2idx(X_train,task_num = 2):\n",
    "    res = []\n",
    "    for i in X_train:\n",
    "        temp = []\n",
    "        for k in range(task_num):\n",
    "            temp.append(k+len(word2idx)+1)\n",
    "        temp.append(1)\n",
    "        for j in i:\n",
    "            temp.append(word2idx[j])\n",
    "        res.append(temp)\n",
    "    res = tf.keras.utils.pad_sequences(res,padding='post',maxlen=200)\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "Tox_names = ['AMES','ClinTox','hERG','DILI','Skin_Reaction','hERG_Karim']\n",
    "x_trains = [] \n",
    "y_trains = []\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "len_20s = []\n",
    "task_labels = []\n",
    "val_task = []\n",
    "for index1,i in enumerate(Tox_names):\n",
    "    try:\n",
    "        \n",
    "        A = tox_process(i)\n",
    "        x_train,x_val,y_train,y_val,len_20 = A.AIS_process(number_of_task=10,token='AIS')\n",
    "        index = 0\n",
    "        res = []\n",
    "        for i in len_20:\n",
    "            res.append(np.average(y_val[index:index+i]))\n",
    "            index = index+i\n",
    "        y_val = np.array(res)\n",
    "        \n",
    "        temp_zip = list(zip(x_train,y_train))\n",
    "        random.shuffle(temp_zip)\n",
    "        x_train,y_train = zip(*temp_zip)\n",
    "        \n",
    "        \n",
    "        temp_x_trains = x_train[:int(len(x_train)/32)*32]\n",
    "        temp_x_trains = np.reshape(temp_x_trains,[-1,32,200])\n",
    "        x_trains += list(temp_x_trains) + list(x_train[int(len(x_train)/32)*32:])\n",
    "        \n",
    "        temp_y_trains = y_train[:int(len(y_train)/32)*32]\n",
    "        temp_y_trains = np.reshape(temp_y_trains,[-1,32])\n",
    "        tmp = list(temp_y_trains) + list(y_train[int(len(y_train)/32)*32:])\n",
    "        y_trains += tmp\n",
    "        \n",
    "        \n",
    "        \n",
    "        task_labels+=[index1]*len(tmp)\n",
    "        \n",
    "        \n",
    "        y_vals.append(y_val)\n",
    "        x_vals.append(x_val)\n",
    "        len_20s.append(len_20)\n",
    "        val_task.append(index1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "Tox_names = ['AMES','ClinTox','hERG','DILI','hERG_Karim','Skin Reaction','Carcinogens_Lagunin']\n",
    "x_trains = [] \n",
    "y_trains = []\n",
    "x_vals = []\n",
    "y_vals = []\n",
    "len_20s = []\n",
    "task_labels = []\n",
    "val_task = []\n",
    "for index1,i in enumerate(Tox_names):\n",
    "    with open(f'./Tox_data/SMILE_Tox_data/{i}','rb') as file:\n",
    "        corpus = pickle.load(file)\n",
    "    spliter = tox_process('temp',0.2,204)\n",
    "    x_train,x_val,y_train,y_val,len_20 = spliter.train_val_split(corpus[0],word2idx,7)\n",
    "    print(y_train)\n",
    "    \"\"\"\n",
    "    with open(f'./data_sets/{i}_train','rb') as file:\n",
    "        X_train,y_train,_ = pickle.load(file)\n",
    "        x_train = w2idx(X_train,0)\n",
    "    with open(f'./data_sets/{i}_val','rb') as file:\n",
    "        X_val,y_val,len_20 = pickle.load(file)\n",
    "        x_val = w2idx(X_val,0)\"\"\"\n",
    "    index = 0\n",
    "    res = []\n",
    "    for i in len_20:\n",
    "        res.append(np.average(y_val[index:index+i]))\n",
    "        index = index+i\n",
    "    y_val = np.array(res)\n",
    "    temp_zip = list(zip(x_train,y_train))\n",
    "    random.shuffle(temp_zip)\n",
    "    x_train,y_train = zip(*temp_zip)\n",
    "    \n",
    "    \n",
    "    temp_x_trains = x_train[:int(len(x_train)/32)*32]\n",
    "    temp_x_trains = np.reshape(temp_x_trains,[-1,32,200])\n",
    "    x_trains += list(temp_x_trains) + list(x_train[int(len(x_train)/32)*32:])\n",
    "    \n",
    "    temp_y_trains = y_train[:int(len(y_train)/32)*32]\n",
    "    temp_y_trains = np.reshape(temp_y_trains,[-1,32])\n",
    "    tmp = list(temp_y_trains) + list(y_train[int(len(y_train)/32)*32:])\n",
    "    y_trains += tmp\n",
    "    \n",
    "    \n",
    "    \n",
    "    task_labels+=[index1]*len(tmp)\n",
    "    \n",
    "    \n",
    "    y_vals.append(y_val)\n",
    "    x_vals.append(x_val)\n",
    "    len_20s.append(len_20)\n",
    "    val_task.append(index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trains[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "temp_zip = list(zip(x_trains,y_trains,task_labels))\n",
    "random.shuffle(temp_zip)\n",
    "\n",
    "x_trains,y_trains,task_labels = zip(*temp_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " '<unknown1>': 3,\n",
       " '<unknown2>': 4,\n",
       " '<unknown3>': 5,\n",
       " '<unknow4>': 6,\n",
       " '<unknown5>': 7,\n",
       " 'C': 8,\n",
       " 'n': 9,\n",
       " '1': 10,\n",
       " 'c': 11,\n",
       " '(': 12,\n",
       " 'N': 13,\n",
       " '2': 14,\n",
       " '[C@H]': 15,\n",
       " '[nH]': 16,\n",
       " 'S': 17,\n",
       " ')': 18,\n",
       " '=': 19,\n",
       " 'O': 20,\n",
       " '[C@@H]': 21,\n",
       " 'F': 22,\n",
       " '[O-]': 23,\n",
       " '[N@@H+]': 24,\n",
       " '3': 25,\n",
       " '[N@H+]': 26,\n",
       " 'o': 27,\n",
       " '4': 28,\n",
       " 'Br': 29,\n",
       " '[nH+]': 30,\n",
       " '[NH+]': 31,\n",
       " '5': 32,\n",
       " '[C@]': 33,\n",
       " '[C@@]': 34,\n",
       " 's': 35,\n",
       " '-': 36,\n",
       " '[NH3+]': 37,\n",
       " '/': 38,\n",
       " '\\\\': 39,\n",
       " 'Cl': 40,\n",
       " '[N+]': 41,\n",
       " '#': 42,\n",
       " '[N-]': 43,\n",
       " '[NH2+]': 44,\n",
       " '[P@]': 45,\n",
       " '[P@@]': 46,\n",
       " '[n-]': 47,\n",
       " '[n+]': 48,\n",
       " '[N@+]': 49,\n",
       " '[N@@+]': 50,\n",
       " 'I': 51,\n",
       " 'P': 52,\n",
       " '[PH+]': 53,\n",
       " '6': 54,\n",
       " '[S@@]': 55,\n",
       " '[Si]': 56,\n",
       " '[S@]': 57,\n",
       " '[o+]': 58,\n",
       " '[S-]': 59,\n",
       " '[O+]': 60,\n",
       " '7': 61,\n",
       " '[S@@+]': 62,\n",
       " '[S@+]': 63,\n",
       " '[S+]': 64,\n",
       " '[P@H]': 65,\n",
       " '[P@@H]': 66,\n",
       " '[SH]': 67,\n",
       " '[s+]': 68,\n",
       " '[P+]': 69,\n",
       " '[PH]': 70,\n",
       " '8': 71,\n",
       " '[Hg]': 72,\n",
       " '.': 73,\n",
       " '[Na]': 74,\n",
       " '[Cl+3]': 75,\n",
       " '[cH-]': 76,\n",
       " '[CH-]': 77,\n",
       " '[CH2-]': 78,\n",
       " '[C-]': 79,\n",
       " '[Cl+2]': 80,\n",
       " '[Cl-]': 81,\n",
       " '[Na+]': 82,\n",
       " '[NH4+]': 83,\n",
       " '[Br-]': 84,\n",
       " '[Li+]': 85,\n",
       " '[Gd+3]': 86,\n",
       " 'B': 87,\n",
       " '[Pt+2]': 88,\n",
       " '[Fe+4]': 89,\n",
       " '*': 90,\n",
       " '[H]': 91,\n",
       " '[N]': 92,\n",
       " '[99Tc]': 93,\n",
       " '[Se]': 94,\n",
       " '[Fe-2]': 95,\n",
       " '[Al]': 96,\n",
       " '[Ca+2]': 97,\n",
       " '[131I]': 98,\n",
       " '[Pt]': 99,\n",
       " '[Bi]': 100,\n",
       " '[123I]': 101,\n",
       " '[Au]': 102,\n",
       " '[201Tl]': 103,\n",
       " '[Cr]': 104,\n",
       " '[Cu]': 105,\n",
       " '[Mn]': 106,\n",
       " '[Zn]': 107,\n",
       " '[As]': 108,\n",
       " '[32P]': 109,\n",
       " '[Ti]': 110,\n",
       " '[I-]': 111,\n",
       " '9': 112,\n",
       " '%10': 113,\n",
       " '%11': 114,\n",
       " '[NH-]': 115,\n",
       " '[K+]': 116,\n",
       " '[B-]': 117,\n",
       " '[Mg+2]': 118,\n",
       " '[se]': 119,\n",
       " '[2H]': 120,\n",
       " '[Ba+2]': 121,\n",
       " '[OH-]': 122,\n",
       " '[Zn+2]': 123,\n",
       " '[Nd+3]': 124,\n",
       " '[Co+3]': 125,\n",
       " '[Ca]': 126,\n",
       " '[15n]': 127,\n",
       " '[CH2]': 128,\n",
       " '[C]': 129,\n",
       " '[CH]': 130,\n",
       " '[O]': 131,\n",
       " '%12': 132,\n",
       " '[OH+]': 133,\n",
       " '[OH2+]': 134,\n",
       " '[Cl]': 135,\n",
       " '[H+]': 136,\n",
       " '[NH]': 137,\n",
       " '[Cd]': 138,\n",
       " '[Cl+]': 139,\n",
       " '[Br+2]': 140,\n",
       " '[S+2]': 141,\n",
       " '[Cu+2]': 142,\n",
       " '[Mn+2]': 143,\n",
       " '[H-]': 144,\n",
       " '[SbH]': 145}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160, 161, 162, 163, 164, 165, 166,   1,   8,   8,  12,  20,  18,\n",
       "         8,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trains[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " bert_tensor_2 (BERT_tensor)  (None, 200, 256)         11497984  \n",
      "                                                                 \n",
      " tf.__operators__.getitem_20  (None, 256)              0         \n",
      "  (SlicingOpLambda)                                              \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,498,241\n",
      "Trainable params: 11,498,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160, 161, 162, 163, 164, 165, 166,   1,  11,  10,  14,   8,   8,\n",
       "        25,   8,  12,  11,  28,  11,  14,  11,  12,  11,  11,  11,  28,\n",
       "        18,  16,  11,  10,  18,   8,   8,  12,   8,  13,  25,   8,  18,\n",
       "         8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trains[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "Steps : 11969 Task : 0, Loss: 0.4109, acc : 0.8187, auc : 0.8925     Task : 1, Loss: 0.1415, acc : 0.9421, auc : 0.8470     Task : 2, Loss: 0.1089, acc : 0.9595, auc : 0.9683     Task : 3, Loss: 0.2655, acc : 0.9025, auc : 0.8481     Task : 4, Loss: 0.4589, acc : 0.7806, auc : 0.8642     Task : 5, Loss: 0.3710, acc : 0.8361, auc : 0.8273     Task : 6, Loss: 0.2086, acc : 0.9091, auc : 0.7886\n",
      "Task is AMES\n",
      "Test accuracy: 0.7925823926925659\n",
      "Test AUC: 0.8696086406707764\n",
      "Test loss: 0.4676143229007721\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9256756901741028\n",
      "Test AUC: 0.847793698310852\n",
      "Test loss: 0.2060948610305786\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8244274854660034\n",
      "Test AUC: 0.843360424041748\n",
      "Test loss: 0.6398007273674011\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7052631378173828\n",
      "Test AUC: 0.8305234909057617\n",
      "Test loss: 0.6484538316726685\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7545555830001831\n",
      "Test AUC: 0.8365218043327332\n",
      "Test loss: 0.5054072141647339\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.7283950448036194\n",
      "Test AUC: 0.6549020409584045\n",
      "Test loss: 0.7545449733734131\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.7857142686843872\n",
      "Test AUC: 0.8731707334518433\n",
      "Test loss: 0.46403905749320984\n",
      "\n",
      "Epoch 2/25\n",
      "Steps : 11969 Task : 0, Loss: 0.3335, acc : 0.8561, auc : 0.9294     Task : 1, Loss: 0.0900, acc : 0.9646, auc : 0.8762     Task : 2, Loss: 0.0696, acc : 0.9748, auc : 0.9737     Task : 3, Loss: 0.1667, acc : 0.9447, auc : 0.8704     Task : 4, Loss: 0.3656, acc : 0.8337, auc : 0.9162     Task : 5, Loss: 0.2654, acc : 0.8997, auc : 0.8714     Task : 6, Loss: 0.1312, acc : 0.9448, auc : 0.8139\n",
      "Task is AMES\n",
      "Test accuracy: 0.8001373410224915\n",
      "Test AUC: 0.8761729001998901\n",
      "Test loss: 0.4751853048801422\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9324324131011963\n",
      "Test AUC: 0.8762441873550415\n",
      "Test loss: 0.20856232941150665\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8167939186096191\n",
      "Test AUC: 0.8536584973335266\n",
      "Test loss: 0.6741931438446045\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test AUC: 0.8309671878814697\n",
      "Test loss: 0.6516901254653931\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7668278217315674\n",
      "Test AUC: 0.8447403907775879\n",
      "Test loss: 0.5139003992080688\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.6666666865348816\n",
      "Test AUC: 0.673202633857727\n",
      "Test loss: 0.9103633761405945\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.875\n",
      "Test AUC: 0.9276422262191772\n",
      "Test loss: 0.3432144820690155\n",
      "\n",
      "Epoch 3/25\n",
      "Steps : 11969 Task : 0, Loss: 0.2682, acc : 0.8858, auc : 0.9540     Task : 1, Loss: 0.0586, acc : 0.9764, auc : 0.8862     Task : 2, Loss: 0.0479, acc : 0.9835, auc : 0.9752     Task : 3, Loss: 0.0934, acc : 0.9717, auc : 0.8830     Task : 4, Loss: 0.2771, acc : 0.8798, auc : 0.9522     Task : 5, Loss: 0.2027, acc : 0.9230, auc : 0.8890     Task : 6, Loss: 0.0802, acc : 0.9761, auc : 0.8220\n",
      "Task is AMES\n",
      "Test accuracy: 0.8111263513565063\n",
      "Test AUC: 0.8764812350273132\n",
      "Test loss: 0.49514061212539673\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9358108043670654\n",
      "Test AUC: 0.8860318660736084\n",
      "Test loss: 0.21684116125106812\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8167939186096191\n",
      "Test AUC: 0.862601637840271\n",
      "Test loss: 0.6853432655334473\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test AUC: 0.8145518898963928\n",
      "Test loss: 0.7065266370773315\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7627370953559875\n",
      "Test AUC: 0.8471079468727112\n",
      "Test loss: 0.5463895797729492\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.6913580298423767\n",
      "Test AUC: 0.6555555462837219\n",
      "Test loss: 0.9736301898956299\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.9107142686843872\n",
      "Test AUC: 0.9162602424621582\n",
      "Test loss: 0.3258461058139801\n",
      "\n",
      "Epoch 4/25\n",
      "Steps : 11969 Task : 0, Loss: 0.2209, acc : 0.9065, auc : 0.9682     Task : 1, Loss: 0.0447, acc : 0.9823, auc : 0.8893     Task : 2, Loss: 0.0350, acc : 0.9897, auc : 0.9758     Task : 3, Loss: 0.0509, acc : 0.9898, auc : 0.8860     Task : 4, Loss: 0.2086, acc : 0.9125, auc : 0.9726     Task : 5, Loss: 0.1553, acc : 0.9459, auc : 0.8984     Task : 6, Loss: 0.0573, acc : 0.9838, auc : 0.8237\n",
      "Task is AMES\n",
      "Test accuracy: 0.8159340620040894\n",
      "Test AUC: 0.8786276578903198\n",
      "Test loss: 0.5262469053268433\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9324324131011963\n",
      "Test AUC: 0.8856170773506165\n",
      "Test loss: 0.236650750041008\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8320610523223877\n",
      "Test AUC: 0.871544599533081\n",
      "Test loss: 0.6645110845565796\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test AUC: 0.7968056797981262\n",
      "Test loss: 0.8129647374153137\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7645965218544006\n",
      "Test AUC: 0.846503734588623\n",
      "Test loss: 0.5944015979766846\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.6913580298423767\n",
      "Test AUC: 0.6797385215759277\n",
      "Test loss: 0.9819198250770569\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.8928571343421936\n",
      "Test AUC: 0.919512152671814\n",
      "Test loss: 0.33124229311943054\n",
      "\n",
      "Epoch 5/25\n",
      "Steps : 11969 Task : 0, Loss: 0.1895, acc : 0.9201, auc : 0.9762     Task : 1, Loss: 0.0356, acc : 0.9861, auc : 0.8911     Task : 2, Loss: 0.0284, acc : 0.9911, auc : 0.9758     Task : 3, Loss: 0.0288, acc : 0.9966, auc : 0.8863     Task : 4, Loss: 0.1628, acc : 0.9333, auc : 0.9826     Task : 5, Loss: 0.1275, acc : 0.9562, auc : 0.9036     Task : 6, Loss: 0.0444, acc : 0.9874, auc : 0.8242\n",
      "Task is AMES\n",
      "Test accuracy: 0.8131868243217468\n",
      "Test AUC: 0.8771863579750061\n",
      "Test loss: 0.5553306937217712\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9324324131011963\n",
      "Test AUC: 0.8161910772323608\n",
      "Test loss: 0.24938121438026428\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8320610523223877\n",
      "Test AUC: 0.8803521990776062\n",
      "Test loss: 0.6660600304603577\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7368420958518982\n",
      "Test AUC: 0.7908163070678711\n",
      "Test loss: 0.8842437863349915\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.767199695110321\n",
      "Test AUC: 0.8515117764472961\n",
      "Test loss: 0.6216621398925781\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.6790123581886292\n",
      "Test AUC: 0.6852940917015076\n",
      "Test loss: 1.0086991786956787\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.875\n",
      "Test AUC: 0.9121951460838318\n",
      "Test loss: 0.32756516337394714\n",
      "\n",
      "Epoch 6/25\n",
      "Steps : 11969 Task : 0, Loss: 0.1671, acc : 0.9299, auc : 0.9810     Task : 1, Loss: 0.0297, acc : 0.9883, auc : 0.8916     Task : 2, Loss: 0.0218, acc : 0.9946, auc : 0.9759     Task : 3, Loss: 0.0193, acc : 0.9982, auc : 0.8863     Task : 4, Loss: 0.1327, acc : 0.9468, auc : 0.9878     Task : 5, Loss: 0.1093, acc : 0.9628, auc : 0.9062     Task : 6, Loss: 0.0342, acc : 0.9904, auc : 0.8249\n",
      "Task is AMES\n",
      "Test accuracy: 0.807692289352417\n",
      "Test AUC: 0.8775336742401123\n",
      "Test loss: 0.5777366757392883\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9358108043670654\n",
      "Test AUC: 0.7974452972412109\n",
      "Test loss: 0.2555094063282013\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.847328245639801\n",
      "Test AUC: 0.8821138143539429\n",
      "Test loss: 0.666102945804596\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7263157963752747\n",
      "Test AUC: 0.783496081829071\n",
      "Test loss: 0.9359551668167114\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7794719338417053\n",
      "Test AUC: 0.8518863916397095\n",
      "Test loss: 0.6552448272705078\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.7037037014961243\n",
      "Test AUC: 0.6833333373069763\n",
      "Test loss: 1.0413557291030884\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.8928571343421936\n",
      "Test AUC: 0.9325202703475952\n",
      "Test loss: 0.33290553092956543\n",
      "\n",
      "Epoch 7/25\n",
      "Steps : 11969 Task : 0, Loss: 0.1502, acc : 0.9376, auc : 0.9843     Task : 1, Loss: 0.0261, acc : 0.9899, auc : 0.8919     Task : 2, Loss: 0.0192, acc : 0.9952, auc : 0.9759     Task : 3, Loss: 0.0140, acc : 0.9993, auc : 0.8864     Task : 4, Loss: 0.1130, acc : 0.9548, auc : 0.9905     Task : 5, Loss: 0.0943, acc : 0.9679, auc : 0.9087     Task : 6, Loss: 0.0273, acc : 0.9927, auc : 0.8249\n",
      "Task is AMES\n",
      "Test accuracy: 0.8090659379959106\n",
      "Test AUC: 0.8731282353401184\n",
      "Test loss: 0.5859732627868652\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9358108043670654\n",
      "Test AUC: 0.7767087817192078\n",
      "Test loss: 0.2778477072715759\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.847328245639801\n",
      "Test AUC: 0.8810298442840576\n",
      "Test loss: 0.6493124961853027\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.75789475440979\n",
      "Test AUC: 0.7877106666564941\n",
      "Test loss: 0.93858402967453\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7772406339645386\n",
      "Test AUC: 0.8503649830818176\n",
      "Test loss: 0.6899015307426453\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.7160493731498718\n",
      "Test AUC: 0.6784313321113586\n",
      "Test loss: 1.129267692565918\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.8928571343421936\n",
      "Test AUC: 0.9121950268745422\n",
      "Test loss: 0.3818378448486328\n",
      "\n",
      "Epoch 8/25\n",
      "Steps : 11969 Task : 0, Loss: 0.1367, acc : 0.9434, auc : 0.9865     Task : 1, Loss: 0.0220, acc : 0.9916, auc : 0.8928     Task : 2, Loss: 0.0177, acc : 0.9958, auc : 0.9760     Task : 3, Loss: 0.0102, acc : 1.0000, auc : 0.8864     Task : 4, Loss: 0.0995, acc : 0.9603, auc : 0.9922     Task : 5, Loss: 0.0825, acc : 0.9707, auc : 0.9101     Task : 6, Loss: 0.0232, acc : 0.9932, auc : 0.8250\n",
      "Task is AMES\n",
      "Test accuracy: 0.7987637519836426\n",
      "Test AUC: 0.8735772967338562\n",
      "Test loss: 0.6112610697746277\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9391891956329346\n",
      "Test AUC: 0.7795288562774658\n",
      "Test loss: 0.2911543846130371\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.8625954389572144\n",
      "Test AUC: 0.8808943033218384\n",
      "Test loss: 0.637694239616394\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7473683953285217\n",
      "Test AUC: 0.7932564616203308\n",
      "Test loss: 0.948360025882721\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7735217809677124\n",
      "Test AUC: 0.848019003868103\n",
      "Test loss: 0.7383654713630676\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.7037037014961243\n",
      "Test AUC: 0.7009803652763367\n",
      "Test loss: 1.150936245918274\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.8928571343421936\n",
      "Test AUC: 0.899186909198761\n",
      "Test loss: 0.352005273103714\n",
      "\n",
      "Epoch 9/25\n",
      "Steps : 771 Task : 0, Loss: 0.1295, acc : 0.9480, auc : 0.9903     Task : 1, Loss: 0.0207, acc : 0.9921, auc : 0.8305     Task : 2, Loss: 0.0176, acc : 0.9946, auc : 0.9565     Task : 3, Loss: 0.0123, acc : 0.9986, auc : 0.9565     Task : 4, Loss: 0.0889, acc : 0.9673, auc : 0.9954     Task : 5, Loss: 0.0684, acc : 0.9714, auc : 0.9984     Task : 6, Loss: 0.0157, acc : 0.9922, auc : 0.8750"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn_reg = tf.keras.losses.MeanSquaredError()\n",
    "acc = np.array([0])\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    loss_list = [[] for i in range(len(Tox_names))]\n",
    "    acc_list = [[] for i in range(len(Tox_names))]\n",
    "    auc_list = [[] for i in range(len(Tox_names))]\n",
    "    for i in range(0, len(temp_zip)):\n",
    "        batch_images = x_trains[i]\n",
    "        batch_images = tf.reshape(batch_images,[-1,200])\n",
    "        batch_labels = y_trains[i]\n",
    "        batch_labels = tf.reshape(batch_labels,[-1])\n",
    "        task = task_labels[i]\n",
    "\n",
    "        if task != -1:\n",
    "            with tf.GradientTape() as tape:\n",
    "                model = globals()[f'Task{task}_model']\n",
    "                logits = model(batch_images)\n",
    "                logits = tf.reshape(logits,[-1])\n",
    "                loss_value = loss_fn(batch_labels, logits)\n",
    "                acc = tf.keras.metrics.Accuracy()(np.round(logits),batch_labels)\n",
    "                auc = tf.keras.metrics.AUC()(batch_labels,logits)\n",
    "                auc = auc.numpy()\n",
    "                loss_value = tf.reduce_mean(loss_value)\n",
    "                loss_list[task].append(loss_value)\n",
    "                acc_list[task].append(acc)\n",
    "                auc_list[task].append(auc)\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        else:\n",
    "            with tf.GradientTape() as tape:\n",
    "                model = globals()[f'Task{task}_model']\n",
    "                logits = model(batch_images)\n",
    "                logits = tf.reshape(logits,[-1])\n",
    "                loss_value = loss_fn_reg(logits,batch_labels)\n",
    "                loss_value = tf.reduce_mean(loss_value)\n",
    "                loss_list[task].append(loss_value)\n",
    "                acc = tf.keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\", dtype=None)(logits,batch_labels)\n",
    "                acc_list[task].append(acc)\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        for l in range(len(Tox_names)):\n",
    "            \n",
    "            temp_loss = np.average(loss_list[l][-10000:])\n",
    "            temp_acc = np.average(acc_list[l][-10000:])\n",
    "            temp_auc = np.average(auc_list[l][-10000:])\n",
    "            if l == 0:\n",
    "                text = \"\\rSteps : {} Task : {}, Loss: {:.4f}, acc : {:.4f}, auc : {:.4f}\".format(i,l,temp_loss,temp_acc,temp_auc)\n",
    "            else:\n",
    "                text += \"     Task : {}, Loss: {:.4f}, acc : {:.4f}, auc : {:.4f}\".format(l,temp_loss,temp_acc,temp_auc)\n",
    "            sys.stdout.write(text)\n",
    "            sys.stdout.flush()\n",
    "    # 각 에포크 종료 후 평가\n",
    "    for temp_index,j in enumerate(val_task):\n",
    "        j = j\n",
    "        val_res = predict(globals()[f'Task{j}_model'],x_vals[temp_index],len_20s[temp_index])\n",
    "        val_res = val_res.reshape(-1)\n",
    "        if j != -1:\n",
    "            acc = tf.keras.metrics.Accuracy()(y_vals[temp_index],np.round(val_res))\n",
    "            auc_res = (AUC()(y_vals[temp_index],val_res)).numpy()\n",
    "            loss = loss_fn(y_vals[temp_index],val_res)\n",
    "            \n",
    "            print(f'\\nTask is {Tox_names[temp_index]}')\n",
    "            print(f\"Test accuracy: {acc}\")\n",
    "            print(f\"Test AUC: {auc_res}\")\n",
    "            print(f\"Test loss: {loss}\\n\")\n",
    "        else:\n",
    "            loss = loss_fn_reg(y_vals[temp_index],val_res)\n",
    "            print(f'\\nTask is {Tox_names[temp_index]}')\n",
    "            print(f\"\\nTest MSE:{loss}\")\n",
    "    for i in range(7):\n",
    "        globals()[f'Task{i}_model'].save_weights(f'./BERT/SMILE_MTL/BERT_model_task{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.46617275>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res = predict(globals()[f'Task{2}_model'],x_vals[2],len_20s[2])\n",
    "val_res = val_res.reshape(-1)\n",
    "loss = loss_fn(y_vals[2],val_res)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.83206105>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Accuracy()(y_vals[2],np.round(val_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals[temp_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<start>',\n",
       " 2: '<end>',\n",
       " 3: '<unknown1>',\n",
       " 4: '<unknown2>',\n",
       " 5: '<unknown3>',\n",
       " 6: '<unknow4>',\n",
       " 7: '<unknown5>',\n",
       " 8: 'C',\n",
       " 9: 'n',\n",
       " 10: '1',\n",
       " 11: 'c',\n",
       " 12: '(',\n",
       " 13: 'N',\n",
       " 14: '2',\n",
       " 15: '[C@H]',\n",
       " 16: '[nH]',\n",
       " 17: 'S',\n",
       " 18: ')',\n",
       " 19: '=',\n",
       " 20: 'O',\n",
       " 21: '[C@@H]',\n",
       " 22: 'F',\n",
       " 23: '[O-]',\n",
       " 24: '[N@@H+]',\n",
       " 25: '3',\n",
       " 26: '[N@H+]',\n",
       " 27: 'o',\n",
       " 28: '4',\n",
       " 29: 'Br',\n",
       " 30: '[nH+]',\n",
       " 31: '[NH+]',\n",
       " 32: '5',\n",
       " 33: '[C@]',\n",
       " 34: '[C@@]',\n",
       " 35: 's',\n",
       " 36: '-',\n",
       " 37: '[NH3+]',\n",
       " 38: '/',\n",
       " 39: '\\\\',\n",
       " 40: 'Cl',\n",
       " 41: '[N+]',\n",
       " 42: '#',\n",
       " 43: '[N-]',\n",
       " 44: '[NH2+]',\n",
       " 45: '[P@]',\n",
       " 46: '[P@@]',\n",
       " 47: '[n-]',\n",
       " 48: '[n+]',\n",
       " 49: '[N@+]',\n",
       " 50: '[N@@+]',\n",
       " 51: 'I',\n",
       " 52: 'P',\n",
       " 53: '[PH+]',\n",
       " 54: '6',\n",
       " 55: '[S@@]',\n",
       " 56: '[Si]',\n",
       " 57: '[S@]',\n",
       " 58: '[o+]',\n",
       " 59: '[S-]',\n",
       " 60: '[O+]',\n",
       " 61: '7',\n",
       " 62: '[S@@+]',\n",
       " 63: '[S@+]',\n",
       " 64: '[S+]',\n",
       " 65: '[P@H]',\n",
       " 66: '[P@@H]',\n",
       " 67: '[SH]',\n",
       " 68: '[s+]',\n",
       " 69: '[P+]',\n",
       " 70: '[PH]',\n",
       " 71: '8',\n",
       " 72: '[Hg]',\n",
       " 73: '.',\n",
       " 74: '[Na]',\n",
       " 75: '[Cl+3]',\n",
       " 76: '[cH-]',\n",
       " 77: '[CH-]',\n",
       " 78: '[CH2-]',\n",
       " 79: '[C-]',\n",
       " 80: '[Cl+2]',\n",
       " 81: '[Cl-]',\n",
       " 82: '[Na+]',\n",
       " 83: '[NH4+]',\n",
       " 84: '[Br-]',\n",
       " 85: '[Li+]',\n",
       " 86: '[Gd+3]',\n",
       " 87: 'B',\n",
       " 88: '[Pt+2]',\n",
       " 89: '[Fe+4]',\n",
       " 90: '*',\n",
       " 91: '[H]',\n",
       " 92: '[N]',\n",
       " 93: '[99Tc]',\n",
       " 94: '[Se]',\n",
       " 95: '[Fe-2]',\n",
       " 96: '[Al]',\n",
       " 97: '[Ca+2]',\n",
       " 98: '[131I]',\n",
       " 99: '[Pt]',\n",
       " 100: '[Bi]',\n",
       " 101: '[123I]',\n",
       " 102: '[Au]',\n",
       " 103: '[201Tl]',\n",
       " 104: '[Cr]',\n",
       " 105: '[Cu]',\n",
       " 106: '[Mn]',\n",
       " 107: '[Zn]',\n",
       " 108: '[As]',\n",
       " 109: '[32P]',\n",
       " 110: '[Ti]',\n",
       " 111: '[I-]',\n",
       " 112: '9',\n",
       " 113: '%10',\n",
       " 114: '%11',\n",
       " 115: '[NH-]',\n",
       " 116: '[K+]',\n",
       " 117: '[B-]',\n",
       " 118: '[Mg+2]',\n",
       " 119: '[se]',\n",
       " 120: '[2H]',\n",
       " 121: '[Ba+2]',\n",
       " 122: '[OH-]',\n",
       " 123: '[Zn+2]',\n",
       " 124: '[Nd+3]',\n",
       " 125: '[Co+3]',\n",
       " 126: '[Ca]',\n",
       " 127: '[15n]',\n",
       " 128: '[CH2]',\n",
       " 129: '[C]',\n",
       " 130: '[CH]',\n",
       " 131: '[O]',\n",
       " 132: '%12',\n",
       " 133: '[OH+]',\n",
       " 134: '[OH2+]',\n",
       " 135: '[Cl]',\n",
       " 136: '[H+]',\n",
       " 137: '[NH]',\n",
       " 138: '[Cd]',\n",
       " 139: '[Cl+]',\n",
       " 140: '[Br+2]',\n",
       " 141: '[S+2]',\n",
       " 142: '[Cu+2]',\n",
       " 143: '[Mn+2]',\n",
       " 144: '[H-]',\n",
       " 145: '[SbH]'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {}\n",
    "\n",
    "\n",
    "for i in word2idx.keys():\n",
    "    idx2word[word2idx[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>[C@H]1([C@H](CC[C@H]2CN3[C@@H](C[C@H]12)c1c(c2c(cccc2)[nH]1)CC3)O)C(OC)=O\n",
      "<start>C1[C@H]2[C@H](C[C@H]3c4c(c5c(cccc5)[nH]4)CCN13)[C@H](C(OC)=O)[C@@H](O)CC2\n",
      "<start>c1cccc2c3CCN4C[C@H]5[C@H](C[C@H]4c3[nH]c12)[C@H](C(OC)=O)[C@H](CC5)O\n",
      "<start>c12[nH]c3cc(OC)ccc3c2CCN2[C@@H]1C[C@@H]1[C@H](C(O)=O)[C@@H](OC)[C@H](O)C[C@@H]1C2\n",
      "<start>[C@H]12C3CCC([C@H]1NCCC2)[C@H]1N3CCc2c3ccccc3[nH]c21\n",
      "<start>c1ccc(c2ccccc21)NCCN\n",
      "<start>c1cc(N2N=C(C(C2=O)/N=N/c2ccc(cc2)S(=O)(O)=O)C(O)=O)ccc1S(=O)(=O)O\n",
      "<start>N(\\c1ccc(cc1)S(=O)(=O)O)=N/C1C(=NN(C1=O)c1ccc(cc1)S(=O)(=O)O)C(=O)O\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(val_res):\n",
    "    if i>0.4 and i < 0.6:\n",
    "        temp = ''\n",
    "        for j in x_val[index]:\n",
    "            try:\n",
    "                temp+=idx2word[j]\n",
    "            except:\n",
    "                pass\n",
    "        print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>C(\\C=O)=C\\O\n",
      "<start>O/C=C\\C=O\n",
      "<start>C(=O)/C=C\\O\n",
      "<start>[C@@H]1(CC[C@H]2CN3CCc4c5c([nH]c4[C@@H]3C[C@@H]2[C@@H]1C(OC)=O)cccc5)O\n",
      "<start>C1CN2C[C@H]3[C@@H]([C@@H]([C@H](CC3)O)C(=O)OC)C[C@H]2c2[nH]c3ccccc3c12\n",
      "<start>[C@H]12[C@@H](CC[C@@H]([C@H]1C(OC)=O)O)CN1[C@@H](C2)c2c(c3c(cccc3)[nH]2)CC1\n",
      "<start>C([C@H]1[C@H]2C[C@@H]3N(CCc4c5c([nH]c43)cccc5)C[C@@H]2CC[C@@H]1O)(=O)OC\n",
      "<start>c1c2c3c([C@H]4N(CC3)C[C@@H]3CC[C@H](O)[C@H]([C@H]3C4)C(OC)=O)[nH]c2ccc1\n",
      "<start>COC([C@@H]1[C@H](CC[C@@H]2[C@@H]1C[C@@H]1N(CCc3c1[nH]c1c3cccc1)C2)O)=O\n",
      "<start>c12c3c([C@@H]4C[C@@H]5[C@@H]([C@@H](O)CC[C@H]5CN4CC3)C(OC)=O)[nH]c2cccc1\n",
      "<start>[C@H]1(O)CC[C@H]2CN3[C@@H](C[C@@H]2[C@@H]1C(OC)=O)c1[nH]c2c(cccc2)c1CC3\n",
      "<start>O[C@H]1CC[C@@H]2[C@@H]([C@@H]1C(OC)=O)C[C@H]1c3[nH]c4ccccc4c3CCN1C2\n",
      "<start>[C@@H]1(O)[C@@H](C(OC)=O)[C@@H]2[C@H](CN3[C@@H](C2)c2[nH]c4ccccc4c2CC3)CC1\n",
      "<start>O=C(OC)[C@@H]1[C@@H](O)CC[C@@H]2[C@@H]1C[C@@H]1N(C2)CCc2c3ccccc3[nH]c12\n",
      "<start>C1[C@@H]2c3[nH]c4cc(OC)ccc4c3CCN2C[C@@H]2[C@H]1[C@H](C(=O)O)[C@H]([C@H](O)C2)OC\n",
      "<start>c1(ccc2c3CCN4C[C@@H]5[C@@H]([C@@H]([C@@H](OC)[C@H](O)C5)C(=O)O)C[C@@H]4c3[nH]c2c1)OC\n",
      "<start>c1cc(cc2c1c1CCN3[C@H](C[C@@H]4[C@@H]([C@@H](OC)[C@@H](C[C@@H]4C3)O)C(=O)O)c1[nH]2)OC\n",
      "<start>[C@H]12[C@H](C[C@H]3N(C1)CCc1c3[nH]c3cc(ccc31)OC)[C@@H]([C@H]([C@H](O)C2)OC)C(O)=O\n",
      "<start>O=C(O)[C@H]1[C@H]2C[C@@H]3c4c(CCN3C[C@H]2C[C@@H](O)[C@@H]1OC)c1ccc(OC)cc1[nH]4\n",
      "<start>C([C@@H]1[C@@H](OC)[C@H](O)C[C@H]2[C@@H]1C[C@@H]1c3c(CCN1C2)c1ccc(OC)cc1[nH]3)(=O)O\n",
      "<start>[C@H]1(C(O)=O)[C@@H]2[C@@H](CN3CCc4c5ccc(OC)cc5[nH]c4[C@H]3C2)C[C@@H](O)[C@@H]1OC\n",
      "<start>c12c3CCN4[C@@H](c3[nH]c1cccc2)C1CCC4[C@@H]2CCCN[C@@H]21\n",
      "<start>C1C2[C@H]3NCCC[C@H]3C(N3CCc4c5ccccc5[nH]c4[C@H]32)C1\n",
      "<start>C12CCC(N3CCc4c5c(cccc5)[nH]c4[C@@H]23)[C@H]2[C@@H]1NCCC2\n",
      "<start>C1N[C@H]2[C@@H](CC1)C1CCC2[C@@H]2c3[nH]c4ccccc4c3CCN21\n",
      "<start>C1N[C@H]2[C@H](C3CCC2[C@@H]2c4c(c5ccccc5[nH]4)CCN23)CC1\n",
      "<start>C1Cc2c([nH]c3ccccc23)[C@@H]2N1C1CCC2[C@H]2NCCC[C@H]21\n",
      "<start>c1ccc2[nH]c3c(CCN4C5CCC([C@H]6NCCC[C@H]65)[C@H]34)c2c1\n",
      "<start>[C@H]12[C@@H](CCCN2)C2N3[C@H](C1CC2)c1[nH]c2c(c1CC3)cccc2\n",
      "<start>C1C[C@@H]2[C@@H](C3[C@H]4N(CCc5c6c(cccc6)[nH]c54)C2CC3)NC1\n",
      "<start>C12CCC([C@H]3NCCC[C@@H]13)[C@@H]1c3c(CCN21)c1c([nH]3)cccc1\n",
      "<start>[C@H]12NCCC[C@H]1C1N3CCc4c5c(cccc5)[nH]c4[C@H]3C2CC1\n",
      "<start>C1CC[C@@H]2[C@H](N1)C1CCC2N2CCc3c([C@@H]12)[nH]c1c3cccc1\n",
      "<start>c1(/C=C/C(O[C@H]2[C@@H]([C@H](O)C[C@](C2)(C(=O)O)O)O)=O)cc(c(O)cc1)O\n",
      "<start>C(O)(=O)[C@]1(O)C[C@@H](O)[C@@H](O)[C@@H](C1)OC(/C=C/c1ccc(c(O)c1)O)=O\n",
      "<start>c1(O)c(O)ccc(c1)/C=C/C(=O)O[C@@H]1C[C@@](O)(C[C@@H](O)[C@H]1O)C(O)=O\n",
      "<start>O[C@@H]1C[C@](C[C@@H](OC(=O)/C=C/c2cc(O)c(O)cc2)[C@@H]1O)(C(=O)O)O\n",
      "<start>O=C(O)[C@]1(C[C@H]([C@@H]([C@@H](C1)O)O)OC(/C=C/c1cc(O)c(O)cc1)=O)O\n",
      "<start>[C@@H]1(O)[C@@H](C[C@@](C[C@H]1OC(/C=C/c1cc(O)c(cc1)O)=O)(O)C(=O)O)O\n",
      "<start>c1(O)c(cc(cc1)/C=C/C(O[C@H]1[C@@H]([C@@H](C[C@](C(O)=O)(O)C1)O)O)=O)O\n",
      "<start>C1[C@](O)(C(O)=O)C[C@H]([C@@H](O)[C@@H]1OC(/C=C/c1ccc(c(O)c1)O)=O)O\n",
      "<start>c1c(/C=C/C(O[C@H]2[C@@H]([C@H](O)C[C@](C2)(C(=O)O)O)O)=O)ccc(O)c1O\n",
      "<start>[C@H]1(C[C@](C(=O)O)(O)C[C@@H](OC(/C=C/c2cc(O)c(O)cc2)=O)[C@@H]1O)O\n",
      "<start>C1[C@H]([C@@H]([C@@H](C[C@@]1(O)C(=O)O)O)O)OC(/C=C/c1ccc(c(c1)O)O)=O\n",
      "<start>C(O[C@@H]1C[C@](C(=O)O)(C[C@@H](O)[C@H]1O)O)(=O)/C=C/c1ccc(O)c(c1)O\n",
      "<start>c1ccc2c(c1NCCN)cccc2\n",
      "<start>c1cc2cccc(NCCN)c2cc1\n",
      "<start>c1c(c2c(cc1)cccc2)NCCN\n",
      "<start>c1cccc2c1cccc2NCCN\n",
      "<start>c12c(cccc2)cccc1NCCN\n",
      "<start>C(CNc1c2ccccc2ccc1)N\n",
      "<start>c12ccccc1cccc2NCCN\n",
      "<start>c1c2ccccc2c(NCCN)cc1\n",
      "<start>c12cccc(NCCN)c2cccc1\n",
      "<start>N(CCN)c1c2ccccc2ccc1\n",
      "<start>c1cc(c2ccccc2c1)NCCN\n",
      "<start>C1(/N=N/c2ccc(cc2)S(=O)(=O)O)C(C(O)=O)=NN(c2ccc(cc2)S(=O)(=O)O)C1=O\n",
      "<start>C1(/N=N/c2ccc(S(O)(=O)=O)cc2)C(N(N=C1C(=O)O)c1ccc(S(=O)(O)=O)cc1)=O\n",
      "<start>N(\\c1ccc(cc1)S(O)(=O)=O)=N/C1C(=O)N(c2ccc(cc2)S(=O)(O)=O)N=C1C(O)=O\n",
      "<start>N1=C(C(O)=O)C(/N=N/c2ccc(cc2)S(=O)(=O)O)C(N1c1ccc(cc1)S(O)(=O)=O)=O\n",
      "<start>O=C(C1C(C(N(N=1)c1ccc(cc1)S(O)(=O)=O)=O)/N=N/c1ccc(S(=O)(O)=O)cc1)O\n",
      "<start>c1c(ccc(c1)S(=O)(=O)O)/N=N/C1C(C(=O)O)=NN(c2ccc(cc2)S(=O)(O)=O)C1=O\n",
      "<start>c1cc(ccc1N1N=C(C(O)=O)C(/N=N/c2ccc(cc2)S(O)(=O)=O)C1=O)S(O)(=O)=O\n",
      "<start>N1(C(C(C(=N1)C(O)=O)/N=N/c1ccc(S(=O)(=O)O)cc1)=O)c1ccc(cc1)S(O)(=O)=O\n",
      "<start>C(=O)(C1C(/N=N/c2ccc(cc2)S(O)(=O)=O)C(N(c2ccc(cc2)S(O)(=O)=O)N=1)=O)O\n",
      "<start>O=S(O)(c1ccc(cc1)N1N=C(C(=O)O)C(/N=N/c2ccc(S(O)(=O)=O)cc2)C1=O)=O\n",
      "<start>OS(=O)(c1ccc(N2C(=O)C(C(=N2)C(=O)O)/N=N/c2ccc(cc2)S(=O)(=O)O)cc1)=O\n",
      "<start>S(O)(c1ccc(/N=N/C2C(N(N=C2C(O)=O)c2ccc(cc2)S(=O)(=O)O)=O)cc1)(=O)=O\n",
      "<start>c1cc(ccc1/N=N/C1C(N(N=C1C(=O)O)c1ccc(cc1)S(O)(=O)=O)=O)S(O)(=O)=O\n",
      "<start>c12c3C[C@H]4N(C)C[C@H](C(N[C@@H](CC)CO)=O)C=C4c2cccc1[nH]c3\n",
      "<start>c1cc2c3c(C[C@@H]4C2=C[C@H](CN4C)C(=O)N[C@@H](CC)CO)c[nH]c3c1\n",
      "<start>c1cc2C3=C[C@@H](C(=O)N[C@@H](CC)CO)CN([C@@H]3Cc3c2c([nH]c3)c1)C\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(val_res):\n",
    "    if i > 0.9:\n",
    "        temp = ''\n",
    "        for j in x_val[index]:\n",
    "            try:\n",
    "                temp+=idx2word[j]\n",
    "            except:\n",
    "                pass\n",
    "        print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task is AMES\n",
      "Test accuracy: 0.7767857313156128\n",
      "Test AUC: 0.8451955318450928\n",
      "Test loss: 0.48885905742645264\n",
      "\n",
      "\n",
      "Task is ClinTox\n",
      "Test accuracy: 0.9256756901741028\n",
      "Test AUC: 0.7087756991386414\n",
      "Test loss: 0.25217902660369873\n",
      "\n",
      "\n",
      "Task is hERG\n",
      "Test accuracy: 0.7938931584358215\n",
      "Test AUC: 0.85514897108078\n",
      "Test loss: 0.48679855465888977\n",
      "\n",
      "\n",
      "Task is DILI\n",
      "Test accuracy: 0.7157894968986511\n",
      "Test AUC: 0.8307453393936157\n",
      "Test loss: 0.5598265528678894\n",
      "\n",
      "\n",
      "Task is hERG_Karim\n",
      "Test accuracy: 0.7188546061515808\n",
      "Test AUC: 0.7918149828910828\n",
      "Test loss: 0.5562483668327332\n",
      "\n",
      "\n",
      "Task is Skin Reaction\n",
      "Test accuracy: 0.6419752836227417\n",
      "Test AUC: 0.6545751690864563\n",
      "Test loss: 0.616245687007904\n",
      "\n",
      "\n",
      "Task is Carcinogens_Lagunin\n",
      "Test accuracy: 0.8928571343421936\n",
      "Test AUC: 0.9235773086547852\n",
      "Test loss: 0.3122290074825287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j,j in enumerate(val_task):\n",
    "    val_res = predict(globals()[f'Task{j}_model'],x_vals[j],len_20s[j])\n",
    "    if j != -1:\n",
    "        acc = tf.keras.metrics.Accuracy()(y_vals[j],np.round(val_res))\n",
    "        auc_res = (AUC()(y_vals[j],val_res)).numpy()\n",
    "        loss = tf.keras.metrics.BinaryCrossentropy()(y_vals[j],val_res)\n",
    "        \n",
    "        print(f'\\nTask is {Tox_names[j]}')\n",
    "        print(f\"Test accuracy: {acc}\")\n",
    "        print(f\"Test AUC: {auc_res}\")\n",
    "        print(f\"Test loss: {loss}\\n\")\n",
    "    else:\n",
    "        loss = tf.keras.metrics.MeanSquaredError()(y_vals[j],val_res)\n",
    "        print(f'\\nTask is {Tox_names[j]}')\n",
    "        print(f\"\\nTest MSE:{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
